{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "modern-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "yaml.warnings({'YAMLLoadWarning': False})\n",
    "import os\n",
    "\n",
    "with open(\"./config.yaml\", 'rb') as f:\n",
    "    config = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compound-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_ROOT = config['IO_OPTION']['OUTPUT_ROOT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-representation",
   "metadata": {},
   "source": [
    "# load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "romance-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python default library\n",
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "# general analysis tool-kit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# original library\n",
    "sys.path.append('/home/hiroki/research/dcase2021_task2/src/functions')\n",
    "import common as com\n",
    "import pytorch_modeler as modeler\n",
    "\n",
    "# etc\n",
    "import yaml\n",
    "yaml.warnings({'YAMLLoadWarning': False})\n",
    "\n",
    "# ML lib\n",
    "from scipy.stats import zscore\n",
    "#from umap import UMAP\n",
    "#from sklearn.mixture import GaussianMixture\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "\n",
    "\n",
    "import librosa\n",
    "import IPython\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-configuration",
   "metadata": {},
   "source": [
    "# load config and set logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "everyday-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder = config['IO_OPTION']['OUTPUT_ROOT']+'/eval_strict_MVG_{0}.log'.format(datetime.date.today())\n",
    "logger = com.setup_logger(log_folder, '01_eval.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-effect",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "piano-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed\n",
    "modeler.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "equivalent-exercise",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/media/hiroki/HDD1TB/research/dcase2021_task2/output/MahalanobisAD_SubSeq/frame64_3/config.yaml'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "############################################################################\n",
    "# Setting I/O path\n",
    "############################################################################\n",
    "# input dirs\n",
    "INPUT_ROOT = config['IO_OPTION']['INPUT_ROOT']\n",
    "dev_dir = INPUT_ROOT + \"/dev_data\"\n",
    "add_dev_dir = INPUT_ROOT + \"/add_dev_data\"\n",
    "# machine type\n",
    "machine_types = os.listdir(dev_dir)\n",
    "# output dirs\n",
    "OUTPUT_ROOT = config['IO_OPTION']['OUTPUT_ROOT']\n",
    "MODEL_DIR = config['IO_OPTION']['OUTPUT_ROOT'] + '/models'\n",
    "TB_DIR = config['IO_OPTION']['OUTPUT_ROOT'] + '/tb'\n",
    "OUT_FEATURE_DIR = OUTPUT_ROOT + '/extraction_features'\n",
    "OUT_SCORE_DIR = OUTPUT_ROOT + '/score_strict'\n",
    "OUT_PRED_DIR = OUTPUT_ROOT + '/pred_strict'\n",
    "#os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(TB_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_FEATURE_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_SCORE_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_PRED_DIR, exist_ok=True)\n",
    "# copy config\n",
    "shutil.copy('./config.yaml', OUTPUT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ef68cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#score = pd.read_csv(f'{OUT_SCORE_DIR}/{machine_types[0]}_score.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f62100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#score.loc['h_mean']['pAUC']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-cradle",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "voluntary-occasion",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['fan', 'gearbox', 'pump', 'slider', 'ToyCar', 'ToyTrain', 'valve']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "machine_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "loving-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = ['train', 'valid_source', 'valid_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "spectacular-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ext_data(machine_type, phase):\n",
    "    input_path = f'{OUT_FEATURE_DIR}/{machine_type}_{phase}_features.pkl'\n",
    "    ext_data = pd.read_pickle(input_path)\n",
    "    \n",
    "    return ext_data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ancient-bowling",
   "metadata": {},
   "source": [
    "machine_type = 'pump'\n",
    "input_path = f'{OUT_FEATURE_DIR}/{machine_type}_features.pkl'\n",
    "ext_data = pd.read_pickle(input_path)\n",
    "\n",
    "\n",
    "data_type = data_types[0]\n",
    "feats = ext_data[data_type]['features']\n",
    "labels = ext_data[data_type]['labels']\n",
    "data_types = [data_type] * len(ext_data[data_type]['labels'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "brazilian-adelaide",
   "metadata": {},
   "source": [
    "for i, data_type in enumerate(data_types):\n",
    "    if i == 0:\n",
    "        feats = ext_data[data_type]['features']\n",
    "        labels = ext_data[data_type]['labels']\n",
    "        data_types = [data_type] * len(ext_data[data_type]['labels'])\n",
    "    else:\n",
    "        feats = np.concatenate([feats, ext_data[data_type]['features']], axis=0)\n",
    "        labels = np.concatenate([labels, ext_data[data_type]['labels']], axis=0)\n",
    "        # data type\n",
    "        data_type = [data_type] * len(ext_data[data_type]['labels'])\n",
    "        data_types = data_types + data_type"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fluid-covering",
   "metadata": {},
   "source": [
    "wav_names = []\n",
    "for wav_name in ext_data[data_type]['wav_names']:\n",
    "    wav_names += wav_name"
   ]
  },
  {
   "cell_type": "raw",
   "id": "chubby-liver",
   "metadata": {},
   "source": [
    "len(wav_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "similar-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train datasets\n",
    "def get_target_names(wav_names):\n",
    "    target_names = []\n",
    "    for wav_name in wav_names:\n",
    "        if 'target' in wav_name:\n",
    "            target_names.append(wav_name)\n",
    "    \n",
    "    return target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4200db4",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "for machine_type in machine_types:\n",
    "    data = load_ext_data(machine_type)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(data['train']['features'], aspect='auto')\n",
    "    plt.title(machine_type)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79976467",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "for machine_type in machine_types:\n",
    "    data = load_ext_data(machine_type)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(data['valid_source']['features'], aspect='auto')\n",
    "    plt.title(machine_type)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7826b281",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "for machine_type in machine_types:\n",
    "    data = load_ext_data(machine_type)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(data['valid_target']['features'], aspect='auto')\n",
    "    plt.title(machine_type)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-adjustment",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53682163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ext_data = load_ext_data(machine_types[2], 'train')\n",
    "#section_types = com.get_section_types(ext_data['train']['wav_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f2496d",
   "metadata": {},
   "source": [
    "- features\n",
    "    - list(5000)\n",
    "- wav_names\n",
    "    - list(5000)\n",
    "- label\n",
    "    - list(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c831ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/media/hiroki/HDD1TB/research/dcase2021_task2/output/MahalanobisAD_SubSeq/frame64_2/extraction_features_revised'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67041083",
   "metadata": {},
   "source": [
    "machine_types = machine_types[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99283f5",
   "metadata": {},
   "source": [
    "for machine_type in machine_types:\n",
    "    print(machine_type)\n",
    "    for phase in ['train', 'valid_source', 'valid_target']:\n",
    "        print(phase)\n",
    "        ext_data = load_ext_data(machine_type, phase)\n",
    "        ext_data_revised = {}\n",
    "        ext_data_revised['features'] = []\n",
    "        ext_data_revised['label'] = []\n",
    "        ext_data_revised['wav_name'] = []\n",
    "        for i in range(len(ext_data)):\n",
    "            ext_data_revised['features'].append(ext_data[i]['features'])\n",
    "            ext_data_revised['label'].append(ext_data[i]['label'])\n",
    "            ext_data_revised['wav_name'].append(ext_data[i]['wav_name'])\n",
    "        del ext_data\n",
    "        save_dir = f'{out_dir}/{machine_type}_{phase}_features.pkl'\n",
    "        pd.to_pickle(ext_data_revised, save_dir)\n",
    "        del ext_data_revised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-chambers",
   "metadata": {},
   "source": [
    "## calc MVG (multivariate Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "load fan\n",
      "calc 0\n",
      "calc 1\n",
      "calc 2\n",
      "calc 3\n",
      "calc 4\n",
      "calc 5\n",
      "load gearbox\n",
      "calc 0\n",
      "calc 1\n",
      "calc 2\n",
      "calc 3\n",
      "calc 4\n",
      "calc 5\n",
      "load pump\n",
      "calc 0\n",
      "calc 1\n",
      "calc 2\n",
      "calc 3\n",
      "calc 4\n",
      "calc 5\n",
      "load slider\n",
      "calc 0\n",
      "calc 1\n",
      "calc 2\n",
      "calc 3\n",
      "calc 4\n",
      "calc 5\n",
      "load ToyCar\n",
      "calc 0\n",
      "calc 1\n",
      "calc 2\n",
      "calc 3\n",
      "calc 4\n",
      "calc 5\n",
      "load ToyTrain\n",
      "calc 0\n",
      "calc 1\n",
      "calc 2\n",
      "calc 3\n",
      "calc 4\n",
      "calc 5\n",
      "load valve\n",
      "calc 0\n",
      "calc 1\n",
      "calc 2\n",
      "calc 3\n",
      "calc 4\n",
      "calc 5\n"
     ]
    }
   ],
   "source": [
    "MVG = {}\n",
    "for machine_type in machine_types:\n",
    "    print(f'load {machine_type}')\n",
    "    MVG[machine_type] = {}\n",
    "    ext_data = load_ext_data(machine_type, 'train')\n",
    "    section_types = com.get_section_types(ext_data['wav_name'])\n",
    "    \n",
    "    for section in np.unique(section_types):\n",
    "        print(f'calc {section}')\n",
    "        MVG[machine_type][section] = {}\n",
    "        idx = np.where(section_types == section)[0]\n",
    "        per_section_samples = []\n",
    "        for idx_ in idx:\n",
    "            per_section_samples.append(ext_data['features'][idx_])\n",
    "        per_section_samples = np.concatenate(per_section_samples, axis=0)\n",
    "        per_section_mean = per_section_samples.mean(axis=0)\n",
    "        I = np.identity(per_section_samples.shape[1])\n",
    "        per_section_cov = np.cov(per_section_samples, rowvar=False) + 0.01 * I\n",
    "        MVG[machine_type][section]['mean'] = per_section_mean\n",
    "        MVG[machine_type][section]['cov'] = per_section_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-payroll",
   "metadata": {},
   "source": [
    "## estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70acf5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ce9e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.to_pickle(MVG, OUT_FEATURE_DIR+'/strict_MVG.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dd27802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_perID(describe_df, max_fpr=0.1):\n",
    "    # ユニークsectionを取得、昇順ソート\n",
    "    sections = np.sort(describe_df['section_types'].unique())\n",
    "\n",
    "    for section in sections:\n",
    "        per_section_df = describe_df[describe_df['section_types'] == section]\n",
    "        per_section_AUC = roc_auc_score(per_section_df['labels'], per_section_df['preds'])\n",
    "        per_section_pAUC = roc_auc_score(per_section_df['labels'], per_section_df['preds'], max_fpr=max_fpr)\n",
    "        # column = [AUC,pAUC], row = index\n",
    "        score_df = pd.DataFrame(np.stack([per_section_AUC, per_section_pAUC]), index=['AUC', 'pAUC']).T\n",
    "        # indexをsectionナンバーにrename\n",
    "        # column = [AUC,pAUC], row = [section]\n",
    "        score_df.index = [section]\n",
    "        if section == 0:\n",
    "            scores_df = score_df.copy()\n",
    "        else:\n",
    "            # 結合\n",
    "            scores_df = scores_df.append(score_df)\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fba37376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mahalanobis(mean, cov, samples):\n",
    "    cov_inv = np.linalg.inv(cov)\n",
    "    # load data\n",
    "    dists = [mahalanobis(sample, mean, cov_inv) for sample in samples]\n",
    "    # np.array\n",
    "    dists = np.array(dists)\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb88810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_anomaly_score(mean, cov_inv, sample, n_hop_frames = 1):\n",
    "    sample = sample[:: n_hop_frames, :]\n",
    "    # load data\n",
    "    dists = [mahalanobis(sample[idx,:], mean, cov_inv) for idx in range(len(sample))]\n",
    "    # np.array\n",
    "    dists = np.array(dists)\n",
    "    return dists.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "#dists = [mahalanobis(sample[idx,:], tr_mean, tr_cov_inv) for idx in range(len(sample))]\n",
    "# np.array\n",
    "#dists = np.array(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9233b44c",
   "metadata": {},
   "source": [
    "## Calc Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c6998d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f33bc3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-05-26 00:53:32,105 - 01_eval.py - INFO - CALC SCORE\n",
      "2021-05-26 00:53:32,106 - 01_eval.py - INFO - fan\n",
      "2021-05-26 00:53:32,560 - 01_eval.py - INFO - Calc Anomaly Score\n",
      " 40%|████      | 80/200 [00:47<01:10,  1.69it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-019eeee7e400>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mext_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 1 sample matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;31m# predict 1sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 pred = calc_mahalanobis(tr_mean,\n\u001b[0m\u001b[1;32m     26\u001b[0m                                         \u001b[0mtr_cov_inv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                         sample)\n",
      "\u001b[0;32m<ipython-input-20-4a9b28734824>\u001b[0m in \u001b[0;36mcalc_mahalanobis\u001b[0;34m(mean, cov, samples)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcov_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmahalanobis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_inv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# np.array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-4a9b28734824>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcov_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmahalanobis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_inv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# np.array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase2021_task2/lib/python3.8/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mmahalanobis\u001b[0;34m(u, v, VI)\u001b[0m\n\u001b[1;32m   1090\u001b[0m     \u001b[0mVI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# valid_dataloaderをシャッフルするとバグるの注意\n",
    "\n",
    "for i, machine_type in enumerate(machine_types):\n",
    "    logger.info('CALC SCORE')\n",
    "    logger.info(machine_type)\n",
    "    # get MVG\n",
    "    #tr_mean = MVG[machine_type]['mean']\n",
    "    #tr_cov = MVG[machine_type]['cov']\n",
    "    # load samples\n",
    "    for phase in ['valid_source', 'valid_target']:\n",
    "        ext_data = load_ext_data(machine_type, phase)\n",
    "        section_types = com.get_section_types(ext_data['wav_name']) # vector\n",
    "        for section in np.unique(section_types): #(0,1,2,3,4,5)\n",
    "            # get MVG\n",
    "            tr_mean = MVG[machine_type][section]['mean']\n",
    "            tr_cov_inv = MVG[machine_type][section]['cov']\n",
    "            tr_cov_inv = np.linalg.inv(tr_cov_inv)\n",
    "            idx = np.where(section_types == section)[0]\n",
    "            # predict\n",
    "            preds = []\n",
    "            logger.info('Calc Anomaly Score')\n",
    "            for idx_ in tqdm(range(len(idx))):\n",
    "                sample = ext_data['features'][idx_] # 1 sample matrix\n",
    "                # predict 1sample\n",
    "                pred = calc_anomaly_score(tr_mean,\n",
    "                                          tr_cov_inv,\n",
    "                                          sample)\n",
    "                preds.append(pred)\n",
    "            preds = np.concatenate(preds)\n",
    "\n",
    "            if section == np.unique(section_types)[0]:\n",
    "                pred_all = preds.copy()\n",
    "            else:\n",
    "                pred_all = np.concatenate([pred_all, preds], axis=0)\n",
    "        # wavname + pred\n",
    "        preds_pd = np.stack([np.array(ext_data['wav_name']), pred_all], axis=1)\n",
    "        preds_pd = pd.DataFrame(preds_pd, columns=['wav_name', 'pred'])\n",
    "        preds_pd.to_csv(OUT_PRED_DIR + f'/pred_{machine_type}_{phase}.csv')\n",
    "        # dataframe作成\n",
    "        describe_df = com.get_pred_discribe(labels=ext_data['labels'],\n",
    "                                            preds=preds,\n",
    "                                            section_types=section_types)\n",
    "        # スコア算出(AUC, pAUC)\n",
    "        scores_df = com.get_score_per_Section(describe_df, max_fpr=0.1)\n",
    "\n",
    "        # 結合(source + target)\n",
    "        if phase == 'valid_source':\n",
    "            scores_df = scores_df.rename(index=lambda num: 'Source_' + f'{num}')\n",
    "            all_scores_df = scores_df.copy()\n",
    "        else:\n",
    "            scores_df = scores_df.rename(index=lambda num: 'Target_' + f'{num}')\n",
    "            all_scores_df = all_scores_df.append(scores_df)\n",
    "        del ext_data\n",
    "            \n",
    "    # 平均\n",
    "    mean_df = pd.DataFrame(all_scores_df.mean(axis=0)).T\n",
    "    mean_df.index = ['mean']\n",
    "    # 調和平均\n",
    "    hmean = scipy.stats.hmean(all_scores_df, axis=0)\n",
    "    hmean_df = pd.DataFrame(hmean, index=['AUC', 'pAUC']).T\n",
    "    hmean_df.index = ['h_mean']\n",
    "    # 結合\n",
    "    all_scores_df = all_scores_df.append(mean_df)\n",
    "    all_scores_df = all_scores_df.append(hmean_df)\n",
    "    # 出力\n",
    "    all_scores_df.to_csv(f'{OUT_SCORE_DIR}/{machine_type}_score.csv')\n",
    "    # display\n",
    "    display(all_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(562800,)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "pred_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-cec4343f28cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds_pd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wav_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_all\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpreds_pd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_pd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wav_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpreds_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUT_PRED_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf'/pred_{machine_type}_{phase}.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# dataframe作成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m describe_df = com.get_pred_discribe(labels=ext_data['labels'],\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase2021_task2/lib/python3.8/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all input arrays must have the same shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "preds_pd = np.stack([np.array(ext_data['wav_name']), pred_all], axis=1)\n",
    "preds_pd = pd.DataFrame(preds_pd, columns=['wav_name', 'pred'])\n",
    "preds_pd.to_csv(OUT_PRED_DIR + f'/pred_{machine_type}_{phase}.csv')\n",
    "# dataframe作成\n",
    "describe_df = com.get_pred_discribe(labels=ext_data['labels'],\n",
    "                                    preds=preds,\n",
    "                                    section_types=section_types)\n",
    "# スコア算出(AUC, pAUC)\n",
    "scores_df = com.get_score_per_Section(describe_df, max_fpr=0.1)\n",
    "\n",
    "# 結合(source + target)\n",
    "if phase == 'valid_source':\n",
    "    scores_df = scores_df.rename(index=lambda num: 'Source_' + f'{num}')\n",
    "    all_scores_df = scores_df.copy()\n",
    "else:\n",
    "    scores_df = scores_df.rename(index=lambda num: 'Target_' + f'{num}')\n",
    "    all_scores_df = all_scores_df.append(scores_df)\n",
    "del ext_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacd7f70",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for machine_type in machine_types:\n",
    "    # get MVG\n",
    "    mean = MVG[machine_type]['mean']\n",
    "    cov_inv = np.linalg.inv(MVG[machine_type]['cov'])\n",
    "    # load data\n",
    "    ext_data = load_ext_data(machine_type)\n",
    "    # calc mahalanobis (Anomaly Score)\n",
    "    valid_source_dists = [mahalanobis(sample, mean, cov_inv) for sample in ext_data['valid_source']['features']]\n",
    "    valid_target_dists = [mahalanobis(sample, mean, cov_inv) for sample in ext_data['valid_target']['features']]\n",
    "    # np.array\n",
    "    valid_source_dists = np.array(valid_source_dists)\n",
    "    valid_target_dists = np.array(valid_target_dists)\n",
    "    # calc AUC\n",
    "    roc_auc = roc_auc_score(ext_data['valid_source']['labels'], valid_source_dists)\n",
    "    logger.info(f'{machine_type} valid_source AUC : {roc_auc}')\n",
    "    roc_auc = roc_auc_score(ext_data['valid_target']['labels'], valid_target_dists)\n",
    "    logger.info(f'{machine_type} valid_target AUC : {roc_auc}')\n",
    "    \n",
    "    plt.figure(figsize=(20,3))\n",
    "    plt.title(f'Source {machine_type}')\n",
    "    plt.plot(valid_source_dists, label='Anomaly Score')\n",
    "    plt.plot(ext_data['valid_source']['labels'], label='Ground Truth')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(20,3))\n",
    "    plt.title(f'Target {machine_type}')\n",
    "    plt.plot(valid_target_dists, label='Anomaly Score')\n",
    "    plt.plot(ext_data['valid_target']['labels'], label='Ground Truth')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-favorite",
   "metadata": {},
   "source": [
    "## calc GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_data = load_ext_data(machine_types[6])\n",
    "gmm = GaussianMixture(n_components=3, random_state=42)\n",
    "gmm.fit(ext_data['train']['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm.bic(ext_data['train']['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gmm.predict(ext_data['train']['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-proposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_covs = gmm.covariances_\n",
    "gmm_means = gmm.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_covs = gmm.covariances_\n",
    "gmm_means = gmm.means_\n",
    "\n",
    "\n",
    "# calc mahalanobis (Anomaly Score)\n",
    "valid_source_dists = [mahalanobis(sample, mean, cov_inv) for sample in ext_data['valid_source']['features']]\n",
    "valid_target_dists = [mahalanobis(sample, mean, cov_inv) for sample in ext_data['valid_target']['features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "for machine_type in machine_types:\n",
    "    # get MVG\n",
    "    mean = MVG[machine_type]['mean']\n",
    "    cov_inv = MVG[machine_type]['cov']\n",
    "    # load data\n",
    "    ext_data = load_ext_data(machine_type)\n",
    "    # calc mahalanobis (Anomaly Score)\n",
    "    valid_source_dists = [mahalanobis(sample, mean, cov_inv) for sample in ext_data['valid_source']['features']]\n",
    "    valid_target_dists = [mahalanobis(sample, mean, cov_inv) for sample in ext_data['valid_target']['features']]\n",
    "    # np.array\n",
    "    valid_source_dists = np.array(valid_source_dists)\n",
    "    valid_target_dists = np.array(valid_target_dists)\n",
    "    # calc AUC\n",
    "    roc_auc = roc_auc_score(ext_data['valid_source']['labels'], valid_source_dists)\n",
    "    logger.info(f'{machine_type} valid_source AUC : {roc_auc}')\n",
    "    roc_auc = roc_auc_score(ext_data['valid_target']['labels'], valid_target_dists)\n",
    "    logger.info(f'{machine_type} valid_target AUC : {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_section_types = gmm.predict(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-statement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(section_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(gmm_section_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-advocacy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd0a935bcfac47a6cff448ff090561199275104f3b78ccc0823d03a5e6446c0f955",
   "display_name": "Python 3.8.8 64-bit ('dcase2021_task2': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "metadata": {
   "interpreter": {
    "hash": "a935bcfac47a6cff448ff090561199275104f3b78ccc0823d03a5e6446c0f955"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}